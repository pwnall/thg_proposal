\section{Motivation}
\label{sec:intro}

In order to achieve certain performance goals, software engineers must often
design systems where the owners of the data being processed are different from
the owners of the computing infrastructure used to process the data, who in
turn might be different from the suppliers of the software that processes the
data. This raises the problem that the data owner must trust both the owner
of the computing infrastructure and the software supplier to handle the data
according to some privacy policy.

The most popular instance of the above problem is cloud computing using public
clouds. For example, CheapoTax, a software provider, might provide tax return
preparation software as a service running on Amazon's public cloud. Users
upload their financial information, encrypted using TLS, to Amazon data
centers, where CheapoTax's computation uses the data to produce tax returns,
which are downloaded by the users in an encrypted form, using TLS. Currently,
the users must trust that neither Amazon nor CheapoTax will record their
private financial information. Users must also hope that neither Amazon's
infrastructure nor CheapoTax's software have bugs that would allow other rogue
actors to obtain the private financial data by running malicious software in
the same public Amazon cloud used by CheapoTax.

Another example of the problem we are aiming to solve is a multiplayer game of
any genre, such as League of Legends \cite{riot2009lol},
World of Warcraft \cite{blizzard2004wow}, StarCraft \cite{blizzard2010sc2}, and
Doom \cite{id2004doom}. The gameplay of many multiplayer games, such as the
ones listed above, rely on the fact that that players can only access a subset
of the game state that is dictated by the units they control. To compensate for
network latencies, many games entrust a player's game client with a superset
of the game state that the user should have access to. For example, in
StarCraft, the game client code running on the players' computers "knows" the
entire state, and is trusted to hide the information that the player should not
have access to \cite{hardy2009cheating}. The other games metioned above also
store information that the player shouldn't access in the game clients, leading
to opportunities for cheating \cite{youtube2013lolcheating}
\cite{youtube2008quake3cheating}.


\subsection{Threat Model}

Our threat model assumes that the infrastructure is shared by multiple ongoing
computations, potentially using software from different mutually distrusting
providers. The operating system and high-level software used to manage the
infrastructure may be malicious, and may cooperate with one or more malicious
pieces of software running on the infrastructure, including the software that
performs computations on the private data that must be protected. The
infrastructure owner may also mount a physical attack by attaching a device to
one of the computer's buses, such as the Front-Side Bus (FSB) used for DRAM
accesses or the PCI Express bus. We consider physical attacks to be
significantly more expensive to carry out than software attacks, and we treat
them separately where it makes sense to do so.

The threat model accurately represents a public cloud. Attackers can rent
resources and run malicious software, as well as run experiments to reveal and
exploit vulnerabilities in the infrastructure software. The programs that run
over the private data can also have vulnerabilities, which can be exploited by
attackers. An attacker can also motivate a datacenter maintainance employee to
attach a physical device to a server, but this attack is significantly harder
to mount than a purely software attack.

In the multiplayer game case, the private data is the full game state, and the
data owner is the same as the software supplier. The infrastructure is the
players' computers. Given that players have an incentive to cheat, it is
reasonable to assume that the infrastructure can behave maliciously. Our system
assumes that the players can exploit any vulnerability available in the game
software. Furthermore, players that desire an unfair advantage might install
software that is specifically designed for cheating. This software may be
running concurrently with the game software, and may include components that
run with OS privileges (e.g., Windows drivers or Linux / Darwin kernel
modules) or even SMM privileges (e.g., BIOS hacks). Last, players are willing
to attach hardware devices (known as \textit{mods} or \textit{modchips}) to
computers or game consoles to be able to cheat \cite{harris2007mod}, so
hardware attacks are even more relevant in the multiplayer game scenario.

Our threat model does not cover attacks that require intimiate knowledge of the
processor's hardware internals. Most importantly, we do not protect against
malicious OS-level software that can abuse a CPU's in-field microcode update
mechanism to create a vulnerability in the processor's security features, or
against attackers that have knowledge of existing vulnerabilities in the CPU.
We also do not protect against attacks that analyze the computer's power
consumption.

Last, the threat model does not include denial of service attacks. Our system
requires the operating system that manages the infrastructure to enable certain
CPU features. We do not trust the operating system, so our system checks for
the features' presence and enablement. If the checks fail, the system refuses
to decrypt private data and to perform any computation. This can lead to a
denial of service attack. At the same time, an attack that compromises the
operating system can cause a denial of service simply by disabling the network
driver, and that cannot be worked around as long as the OS is untrusted.
